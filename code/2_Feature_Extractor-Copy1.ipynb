{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T22:49:06.397456Z",
     "start_time": "2019-12-04T22:48:58.724478Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Nov.29, modify and see how long it takes to run \n",
    "from keras.applications import VGG16\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread  #installed skimage - image processing library for sklearn\n",
    "from skimage.transform import resize \n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T22:49:06.406370Z",
     "start_time": "2019-12-04T22:49:06.400035Z"
    }
   },
   "outputs": [],
   "source": [
    "#my imports\n",
    "from keras.preprocessing import image\n",
    "from keras_applications import imagenet_utils\n",
    "#see doc for built-in functions https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py#L157\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T22:49:37.644452Z",
     "start_time": "2019-12-04T22:49:37.345699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project\r\n"
     ]
    }
   ],
   "source": [
    "#shoe_list = !ls ZShoes/Images/\n",
    "\n",
    "#! - runs command line\n",
    "#!ls project5data/2017_140k/recipe_photos/bbc_photos/pages-photos\n",
    "!pwd\n",
    "bbc_list = !ls /Users/xinrucheng/Documents/Metis_bootcamp/week_9/project5data/2017_140k/recipe_photos/bbc_photos/pages-photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T22:49:39.420548Z",
     "start_time": "2019-12-04T22:49:39.414357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bbc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T22:49:41.578353Z",
     "start_time": "2019-12-04T22:49:41.570372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'almond_and_lemon_polenta_21317_16x9.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T22:23:15.183798Z",
     "start_time": "2019-11-29T22:23:15.178010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPython.utils.text.SList"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bbc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shoe_number = [int(x.split('.')[0]) for x in shoe_list]\n",
    "#shoe_number.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shoe_number[:5] # may need numbers later to grab every 10 images or so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:39:00.273938Z",
     "start_time": "2019-11-30T22:38:48.680296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/anaconda/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# load VGG16\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:54:35.407397Z",
     "start_time": "2019-11-29T21:54:35.384592Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:39:00.295314Z",
     "start_time": "2019-11-30T22:39:00.282459Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_pre_process(img_file):\n",
    "    img = imread(img_file)  \n",
    "    img = resize(img, (224, 224), preserve_range=True).astype(np.float32) #resize image\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img) #keras preprocessing function\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:39:00.310486Z",
     "start_time": "2019-11-30T22:39:00.298920Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/anaconda/envs/metis/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"fc...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(input=model.input, output=model.get_layer('fc2').output) # gets the output in fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_images(directory):\n",
    "#     '''stores all images in directory into a list'''\n",
    "#     img_lst = []\n",
    "#     for entry in os.scandir(directory): #loop through files in directory, path is file path of folder containing images\n",
    "#         if entry.path == directory + '/.DS_Store':\n",
    "#             continue  #avoid reading mac os's .DS_Store as an image\n",
    "#         else:\n",
    "#             img_lst.append(entry.path)\n",
    "#     return img_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that can get the data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:14:53.358705Z",
     "start_time": "2019-11-30T13:14:53.351274Z"
    }
   },
   "outputs": [],
   "source": [
    "#def process_data(start, end, directory):\n",
    "def process_data(imglist,directory):\n",
    "    out1 = []\n",
    "    print(len(imglist))\n",
    "    for file in imglist:\n",
    "        #print(file)\n",
    "        filepath = directory + file\n",
    "        #print(filepath)\n",
    "        im = image_pre_process(filepath)\n",
    "        out = model2.predict(im)\n",
    "        out1.append(out[0])\n",
    "        if len(out1) %10 == 0:\n",
    "            print(str(len(out1)) + ' out of ' + str(len(imglist)) + ' done')\n",
    "    return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:39:04.965981Z",
     "start_time": "2019-11-30T22:39:04.958744Z"
    }
   },
   "outputs": [],
   "source": [
    "bbc_path = 'project5data/2017_140k/recipe_photos/bbc_photos/pages-photos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T00:25:22.220540Z",
     "start_time": "2019-11-30T00:23:54.859238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n",
      "60 out of 100 done\n",
      "70 out of 100 done\n",
      "80 out of 100 done\n",
      "90 out of 100 done\n",
      "100 out of 100 done\n"
     ]
    }
   ],
   "source": [
    "out1 = process_data(bbc_list[:100], bbc_path)\n",
    "res = pd.DataFrame(out1)\n",
    "\n",
    "#takes 1min27s locally, 1min2s on aws, not that much advantage for aws?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = process_data(bbc_list[:100], bbc_path)\n",
    "res = pd.DataFrame(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T00:28:37.945863Z",
     "start_time": "2019-11-30T00:28:37.749022Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if file has already started it starts on next image, otherwise, at the beginning\n",
    "list_names = !ls\n",
    "if 'Features.csv' in list_names:\n",
    "    df = pd.read_csv('Features.csv')\n",
    "    num_start = df.shape[0]\n",
    "else:\n",
    "    num_start = 1\n",
    "num_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T00:28:40.894728Z",
     "start_time": "2019-11-30T00:28:38.834489Z"
    }
   },
   "outputs": [],
   "source": [
    "savetopath = '/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project/data/processed/'\n",
    "\n",
    "#append processing results to csv:\n",
    "if num_start==1:\n",
    "    res.to_csv(savetopath + 'bbcFeatures.csv')\n",
    "else:\n",
    "    with open(savetopath + 'bbcFeatures.csv', 'a') as f:\n",
    "        res.to_csv(f, header = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T00:59:12.512004Z",
     "start_time": "2019-11-30T00:46:15.337314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 51\n",
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n",
      "60 out of 100 done\n",
      "70 out of 100 done\n",
      "80 out of 100 done\n",
      "90 out of 100 done\n",
      "100 out of 100 done\n",
      "10.0 20.0\n",
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n",
      "60 out of 100 done\n",
      "70 out of 100 done\n",
      "80 out of 100 done\n",
      "90 out of 100 done\n",
      "100 out of 100 done\n",
      "10.0 20.0\n",
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n",
      "60 out of 100 done\n",
      "70 out of 100 done\n",
      "80 out of 100 done\n",
      "90 out of 100 done\n",
      "100 out of 100 done\n",
      "10.0 20.0\n",
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n",
      "60 out of 100 done\n",
      "70 out of 100 done\n",
      "80 out of 100 done\n",
      "90 out of 100 done\n",
      "100 out of 100 done\n",
      "10.0 20.0\n",
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n",
      "60 out of 100 done\n",
      "70 out of 100 done\n",
      "80 out of 100 done\n",
      "90 out of 100 done\n",
      "100 out of 100 done\n",
      "10.0 20.0\n",
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n",
      "60 out of 100 done\n",
      "70 out of 100 done\n",
      "80 out of 100 done\n",
      "90 out of 100 done\n",
      "100 out of 100 done\n",
      "10.0 20.0\n",
      "100\n",
      "10 out of 100 done\n",
      "20 out of 100 done\n",
      "30 out of 100 done\n",
      "40 out of 100 done\n",
      "50 out of 100 done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-6729e6101f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#res['shoe_number'] = pd.DataFrame(list(range(start,end)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-128-913d81b47681>\u001b[0m in \u001b[0;36mprocess_data\u001b[0;34m(imglist, directory)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(filepath)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_pre_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#modify? storing all 100 in df right now\n",
    "\n",
    "val = 10\n",
    "data = bbc_list[:100]\n",
    "\n",
    "while num_start<=len(data):\n",
    "# for i in range(shoe_num_start,shoe_num_start+val):#range(1,int(np.ceil(len(shoe_number)/val))):\n",
    "    start = num_start\n",
    "    end = min(start+val,len(data))\n",
    "    print(start,end)\n",
    "    \n",
    "    out1 = process_data(data, bbc_path)\n",
    "    res = pd.DataFrame(out1)\n",
    "    #res['shoe_number'] = pd.DataFrame(list(range(start,end)))\n",
    "    #res.set_index('shoe_number', inplace=True)  #don't have recipes numbered!*\n",
    "\n",
    "    if num_start==1:\n",
    "        res.to_csv('test.csv')\n",
    "    else:\n",
    "        with open('test.csv', 'a') as f:\n",
    "            res.to_csv(f, header = False)\n",
    "    num_start+=val\n",
    "    num_start = min(num_start,len(data)/val) #to start where it left off\n",
    "    \n",
    "    \n",
    "    #keeps looping after 100! need to fix this later (optimizing get features code, not urgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T00:45:39.901100Z",
     "start_time": "2019-11-30T00:45:39.893780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = bbc_list[:100]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T22:37:18.955023Z",
     "start_time": "2019-11-29T22:36:12.609569Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.       , 3.509541 , 0.       , ..., 0.       , 2.6794884,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.01787621, 2.7380893 , 0.        , ..., 0.        , 4.274214  ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 1.1794713, 0.5491981,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 0.4681242, 0.       , ..., 0.       , 4.0932627,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.        , 0.        , 2.5906568 , ..., 1.1783607 , 0.59872377,\n",
       "        2.223511  ], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 0.        , 0.48991835,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 1.0170354, 0.       , ..., 0.       , 4.9734263,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.31084102, 3.2480204 , 0.        , ..., 0.        , 1.3381103 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.       , 0.5473187,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.        , 0.2740387 , 0.        , ..., 0.03427231, 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.       , 1.3170042,\n",
       "        0.       ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.       , 0.8235601, 0.       , ..., 0.       , 1.2870092,\n",
       "        0.564378 ], dtype=float32),\n",
       " array([0.       , 2.4952419, 0.       , ..., 4.734845 , 2.089328 ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 3.7539577, 0.       , ..., 0.       , 0.       ,\n",
       "        1.4775083], dtype=float32),\n",
       " array([0.       , 0.4199108, 0.       , ..., 0.       , 6.0549593,\n",
       "        0.       ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.       , 0.1790278,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.7535254, 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 1.6367182, 0.       , ..., 0.       , 2.3212035,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.      , 0.      , 0.      , ..., 4.488822, 0.      , 0.      ],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([1.2502227 , 0.        , 0.        , ..., 0.        , 0.23721601,\n",
       "        1.4529551 ], dtype=float32),\n",
       " array([1.4104776 , 0.26237816, 0.        , ..., 1.558018  , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.      , 0.      , 0.      , ..., 0.      , 0.      , 4.949887],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.       , 0.       , 3.0422716, ..., 0.       , 2.2605312,\n",
       "        0.       ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 1.9872735 , 0.55774873,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.4985431], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.        , 0.86268044, 0.1821121 , ..., 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 2.2466304 , 0.00348854, ..., 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 1.0001738 , 1.4434755 ,\n",
       "        0.70871454], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.       , 4.0071425,\n",
       "        0.       ], dtype=float32),\n",
       " array([1.0474739, 1.2536552, 0.       , ..., 0.       , 5.693501 ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 3.9022183, 0.       , ..., 0.       , 3.2202933,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 1.729522 , 0.       , ..., 4.9382467, 2.8164487,\n",
       "        0.       ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.0898847, 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 0.61309814, 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 4.1176443 , 4.2213206 ,\n",
       "        0.16917041], dtype=float32),\n",
       " array([0.        , 0.25733256, 0.        , ..., 0.        , 1.543185  ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 4.9686847, 0.       , ..., 0.       , 4.6621065,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 1.8370371, 0.       , ..., 0.       , 4.269782 ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.        , 0.9236294 , 0.        , ..., 0.        , 0.28701454,\n",
       "        0.        ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.9740131, 0.       , 0.       , ..., 0.       , 4.6610975,\n",
       "        1.8456857], dtype=float32),\n",
       " array([0.        , 0.        , 0.15622404, ..., 0.03917187, 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 0.        , 1.1362557 , ..., 2.9849043 , 0.18668829,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 0.       , 0.8586659, ..., 1.1320653, 1.4890819,\n",
       "        0.       ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.       , 1.2152268, 0.       , ..., 0.       , 1.8732011,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 0.       , 3.0655866, ..., 0.       , 1.9698937,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 1.3397481, 2.2154334,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.6478395, 3.556248 , 0.       , ..., 0.       , 4.3113446,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.14828193, 4.5293674 , 0.25242186, ..., 2.5493042 , 2.0088258 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([1.4689233 , 0.        , 3.8302183 , ..., 0.20990431, 1.9599228 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 2.3744936, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.8587293 , 2.2483683 , 0.        , ..., 0.56196266, 3.370799  ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.02508342, 3.442454  , 0.        , ..., 0.        , 3.3306434 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 0.8405163, 0.       , ..., 2.8179796, 0.8055745,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 0.       , 0.605837 , ..., 1.1852956, 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.8343961, 1.1137099, 0.       , ..., 3.2899692, 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.      , 0.      , 0.      , ..., 2.519701, 0.      , 0.      ],\n",
       "       dtype=float32),\n",
       " array([0.      , 0.      , 0.      , ..., 2.308195, 0.      , 0.      ],\n",
       "       dtype=float32),\n",
       " array([0.        , 0.02194455, 0.        , ..., 1.024018  , 0.8333014 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 0.        , 0.20966834, ..., 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 2.3168828, 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.       , 3.0843587, 0.       , ..., 0.       , 0.7159637,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 0.09540695, 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.        , 0.30191576, 0.79187894, ..., 0.9091239 , 1.3926966 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 0.18240309, 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.9134775, 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 3.0654097, 0.       , ..., 3.6479528, 2.920045 ,\n",
       "        0.       ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 0.        , 0.26693317,\n",
       "        0.        ], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 0.05815592, 4.9724154 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.23430303, 3.9931803 , 0.        , ..., 0.40170336, 2.2301266 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 0.59393567, 1.3573768 , ..., 0.        , 0.48928142,\n",
       "        0.17379889], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       " array([0.       , 0.       , 0.6417977, ..., 0.       , 1.6690359,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.57337016], dtype=float32),\n",
       " array([0.        , 0.01667848, 0.        , ..., 0.3550446 , 0.        ,\n",
       "        0.62262535], dtype=float32),\n",
       " array([0.        , 0.        , 0.        , ..., 3.2067192 , 0.34003198,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.       , 5.1202145, 0.       , ..., 0.       , 1.5392568,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 1.4263122, 0.       , ..., 0.       , 0.2712827,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 2.210794 , 0.       , ..., 4.3434734, 1.4591234,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 0.7170311, 0.5525639, ..., 0.       , 0.7687285,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.       , 1.8572975, 0.       , ..., 0.       , 1.1537161,\n",
       "        0.       ], dtype=float32),\n",
       " array([0.        , 0.74915946, 0.        , ..., 3.0085907 , 3.9619179 ,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 1.3688362 , 0.        , ..., 0.        , 0.83149934,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 0.        , 2.338125  , ..., 0.        , 2.1347778 ,\n",
       "        0.15965968], dtype=float32),\n",
       " array([0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.8370014], dtype=float32),\n",
       " array([0.54624754, 0.        , 1.727902  , ..., 0.        , 3.1018395 ,\n",
       "        0.        ], dtype=float32)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_path = 'project5data/2017_140k/recipe_photos/bbc_photos/pages-photos/'\n",
    "process_data(bbc_list[:100], bbc_path)\n",
    "#appending 2k images to list also slow? \n",
    "#try first 100: took 1min6s ==> ~0.66s per image, ~24min for 2k images? faster than my code (~1s per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T22:57:56.131601Z",
     "start_time": "2019-11-29T22:57:56.124844Z"
    }
   },
   "outputs": [],
   "source": [
    "# def progressbar(it, prefix=\"\", size=60, file=sys.stdout):\n",
    "#     count = len(it)\n",
    "#     def show(j):\n",
    "#         x = int(size*j/count)\n",
    "#         file.write(\"%s[%s%s] %i/%i\\r\" % (prefix, \"#\"*x, \".\"*(size-x), j, count))\n",
    "#         file.flush()        \n",
    "#     show(0)\n",
    "#     for i, item in enumerate(it):\n",
    "#         yield item\n",
    "#         show(i+1)\n",
    "#     file.write(\"\\n\")\n",
    "#     file.flush()  #really slows things down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:19:58.004971Z",
     "start_time": "2019-11-29T22:57:57.974571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing: [########################################] 20/20\n"
     ]
    }
   ],
   "source": [
    "for i in progressbar(range(20), \"Computing: \", 40):\n",
    "\n",
    "#out1 = process_data(imglist,directory)\n",
    "    out1 = process_data(bbc_list[:100], bbc_path) #print num iteration within process_data ftn**\n",
    "    res = pd.DataFrame(out1)\n",
    "    \n",
    "    #~0.66s per image, expect ~1min for 100 images, ~24min for 2k images? \n",
    "    #already took 2mins for 1/20 = 5 images, although right now I'm appending 100 images to dataframe. Memory pressure looks ok though\n",
    "    #took 22mins for 100 images, not proportional? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T00:00:16.023514Z",
     "start_time": "2019-11-30T00:00:15.156026Z"
    }
   },
   "outputs": [],
   "source": [
    "# outtest = process_data(bbc_list[:100], bbc_path)\n",
    "restest = pd.DataFrame(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:35:14.805620Z",
     "start_time": "2019-11-29T23:35:14.800985Z"
    }
   },
   "outputs": [],
   "source": [
    "#or skip for now? images not numbered\n",
    "\n",
    "# val = 10\n",
    "\n",
    "# while shoe_num_start<=len(shoe_number):\n",
    "# # for i in range(shoe_num_start,shoe_num_start+val):#range(1,int(np.ceil(len(shoe_number)/val))):\n",
    "#     start = shoe_num_start\n",
    "#     end = min(start+val,len(shoe_number))\n",
    "#     print(start,end)\n",
    "#     out1 = process_data(start, end)\n",
    "#     res = pd.DataFrame(out1)\n",
    "#     res['shoe_number'] = pd.DataFrame(list(range(start,end)))\n",
    "#     res.set_index('shoe_number', inplace=True)\n",
    "\n",
    "#     if shoe_num_start==1:\n",
    "#         res.to_csv('Features.csv')\n",
    "#     else:\n",
    "#         with open('Features.csv', 'a') as f:\n",
    "#             res.to_csv(f, header = False)\n",
    "#     shoe_num_start+=val\n",
    "#     shoe_num_start = min(shoe_num_start,len(shoe_number)) #to start where it left off\n",
    "    \n",
    "    #workaround for not having an image number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quickly check cos sim of the first 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:39:22.005629Z",
     "start_time": "2019-11-29T23:39:21.999922Z"
    }
   },
   "outputs": [],
   "source": [
    "def cos_sim_vs_all(imageft, datasetft):\n",
    "    '''Find the pairwise cosine similarity between features of the chosen image and all the images in the dataset'''\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    sim_list = []\n",
    "    for i in range(len(datasetft)):\n",
    "        cos_sim = cosine_similarity(imageft, datasetft.iloc[i].values.reshape(1,-1)) \n",
    "        sim_list.append(cos_sim)\n",
    "    return np.array(sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:46:31.511601Z",
     "start_time": "2019-11-29T23:46:31.503375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#might help to number the recipes to index them?\n",
    "tartft = pd.DataFrame(res.iloc[43])#'appletartmamanblanc_93268_16x9'\n",
    "type(tartft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:46:55.245403Z",
     "start_time": "2019-11-29T23:46:55.239296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tartft.shape #why transposed? dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:41:12.342257Z",
     "start_time": "2019-11-29T23:41:12.304026Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 1 while Y.shape[1] == 4096",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-3b408e0e37fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcos_sim_vs_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtartft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-0375522164be>\u001b[0m in \u001b[0;36mcos_sim_vs_all\u001b[0;34m(imageft, datasetft)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msim_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0msim_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    123\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[1;32m    124\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m--> 125\u001b[0;31m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 1 while Y.shape[1] == 4096"
     ]
    }
   ],
   "source": [
    "#cos_sim_vs_all(tartft, res)\n",
    "#don't need to use self-defined function here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:48:14.984359Z",
     "start_time": "2019-11-29T23:48:14.706268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(np.array(tartft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T23:49:48.397112Z",
     "start_time": "2019-11-29T23:49:48.377934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(np.array(res.iloc[43]).reshape(1, -1)) #cos similarity with itself is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim_vs_all(imageft, datasetft):\n",
    "    '''Find the pairwise cosine similarity between features of the chosen image and all the images in the dataset'''\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    sim_list = []\n",
    "    for i in range(len(datasetft)):\n",
    "        cos_sim = cosine_similarity(imageft, datasetft.iloc[i].values.reshape(1,-1)) \n",
    "        sim_list.append(cos_sim)\n",
    "    return np.array(sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T23:36:39.657887Z",
     "start_time": "2019-11-30T23:36:37.887594Z"
    }
   },
   "outputs": [],
   "source": [
    "alr_list= !ls /Users/xinrucheng/Documents/Metis_bootcamp/week_9/project5data/2017_140k/recipe_photos/allre_images/userphotos/250x250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T23:36:41.053814Z",
     "start_time": "2019-11-30T23:36:41.034718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35299"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:39:27.357606Z",
     "start_time": "2019-11-30T22:39:27.351944Z"
    }
   },
   "outputs": [],
   "source": [
    "#modified from featureextractor allrecipes aws:\n",
    "alrpath = '/Users/xinrucheng/Documents/Metis_bootcamp/week_9/project5data/2017_140k/recipe_photos/allre_images/userphotos/250x250/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:30:44.870586Z",
     "start_time": "2019-11-30T13:17:46.898165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "10 out of 1000 done\n",
      "20 out of 1000 done\n",
      "30 out of 1000 done\n",
      "40 out of 1000 done\n",
      "50 out of 1000 done\n",
      "60 out of 1000 done\n",
      "70 out of 1000 done\n",
      "80 out of 1000 done\n",
      "90 out of 1000 done\n",
      "100 out of 1000 done\n",
      "110 out of 1000 done\n",
      "120 out of 1000 done\n",
      "130 out of 1000 done\n",
      "140 out of 1000 done\n",
      "150 out of 1000 done\n",
      "160 out of 1000 done\n",
      "170 out of 1000 done\n",
      "180 out of 1000 done\n",
      "190 out of 1000 done\n",
      "200 out of 1000 done\n",
      "210 out of 1000 done\n",
      "220 out of 1000 done\n",
      "230 out of 1000 done\n",
      "240 out of 1000 done\n",
      "250 out of 1000 done\n",
      "260 out of 1000 done\n",
      "270 out of 1000 done\n",
      "280 out of 1000 done\n",
      "290 out of 1000 done\n",
      "300 out of 1000 done\n",
      "310 out of 1000 done\n",
      "320 out of 1000 done\n",
      "330 out of 1000 done\n",
      "340 out of 1000 done\n",
      "350 out of 1000 done\n",
      "360 out of 1000 done\n",
      "370 out of 1000 done\n",
      "380 out of 1000 done\n",
      "390 out of 1000 done\n",
      "400 out of 1000 done\n",
      "410 out of 1000 done\n",
      "420 out of 1000 done\n",
      "430 out of 1000 done\n",
      "440 out of 1000 done\n",
      "450 out of 1000 done\n",
      "460 out of 1000 done\n",
      "470 out of 1000 done\n",
      "480 out of 1000 done\n",
      "490 out of 1000 done\n",
      "500 out of 1000 done\n",
      "510 out of 1000 done\n",
      "520 out of 1000 done\n",
      "530 out of 1000 done\n",
      "540 out of 1000 done\n",
      "550 out of 1000 done\n",
      "560 out of 1000 done\n",
      "570 out of 1000 done\n",
      "580 out of 1000 done\n",
      "590 out of 1000 done\n",
      "600 out of 1000 done\n",
      "610 out of 1000 done\n",
      "620 out of 1000 done\n",
      "630 out of 1000 done\n",
      "640 out of 1000 done\n",
      "650 out of 1000 done\n",
      "660 out of 1000 done\n",
      "670 out of 1000 done\n",
      "680 out of 1000 done\n",
      "690 out of 1000 done\n",
      "700 out of 1000 done\n",
      "710 out of 1000 done\n",
      "720 out of 1000 done\n",
      "730 out of 1000 done\n",
      "740 out of 1000 done\n",
      "750 out of 1000 done\n",
      "760 out of 1000 done\n",
      "770 out of 1000 done\n",
      "780 out of 1000 done\n",
      "790 out of 1000 done\n",
      "800 out of 1000 done\n",
      "810 out of 1000 done\n",
      "820 out of 1000 done\n",
      "830 out of 1000 done\n",
      "840 out of 1000 done\n",
      "850 out of 1000 done\n",
      "860 out of 1000 done\n",
      "870 out of 1000 done\n",
      "880 out of 1000 done\n",
      "890 out of 1000 done\n",
      "900 out of 1000 done\n",
      "910 out of 1000 done\n",
      "920 out of 1000 done\n",
      "930 out of 1000 done\n",
      "940 out of 1000 done\n",
      "950 out of 1000 done\n",
      "960 out of 1000 done\n",
      "970 out of 1000 done\n",
      "980 out of 1000 done\n",
      "990 out of 1000 done\n",
      "1000 out of 1000 done\n"
     ]
    }
   ],
   "source": [
    "out1 = process_data(alr_list[3001:4001], alrpath)\n",
    "res = pd.DataFrame(out1)\n",
    "\n",
    "#600 images, 8mins locally\n",
    "#600-800, 2mins for 200 images, normal?\n",
    "#13mins total, versue 11mins on aws for 1000 images - small enough chunks, can run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:30:54.360558Z",
     "start_time": "2019-11-30T13:30:44.877841Z"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv('allreFeatures4001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:39:36.924662Z",
     "start_time": "2019-11-30T22:39:36.912053Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(imglist,directory):\n",
    "    out1 = []\n",
    "    print(len(imglist))\n",
    "    for file in imglist:\n",
    "        #print(file)\n",
    "        filepath = directory + file\n",
    "        #print(filepath)\n",
    "        im = image_pre_process(filepath)\n",
    "        out = model2.predict(im)\n",
    "        out1.append(out[0])\n",
    "        if len(out1) %100 == 0:\n",
    "            print(str(len(out1)) + ' out of ' + str(len(imglist)) + ' done')\n",
    "    return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:44:49.773590Z",
     "start_time": "2019-11-30T13:33:59.599922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "100 out of 1000 done\n",
      "200 out of 1000 done\n",
      "300 out of 1000 done\n",
      "400 out of 1000 done\n",
      "500 out of 1000 done\n",
      "600 out of 1000 done\n",
      "700 out of 1000 done\n",
      "800 out of 1000 done\n",
      "900 out of 1000 done\n",
      "1000 out of 1000 done\n"
     ]
    }
   ],
   "source": [
    "out1 = process_data(alr_list[4001:5001], alrpath)\n",
    "res = pd.DataFrame(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:39:41.195345Z",
     "start_time": "2019-11-30T22:39:41.190914Z"
    }
   },
   "outputs": [],
   "source": [
    "savetopath = '/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project/data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T13:45:53.855946Z",
     "start_time": "2019-11-30T13:45:43.917820Z"
    }
   },
   "outputs": [],
   "source": [
    "res.to_csv(savetopath + 'allreFeatures5001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:44:43.958971Z",
     "start_time": "2019-11-30T22:44:43.946333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allreFeatures1001.csv', 'allreFeatures2001.csv', 'allreFeatures3001.csv', 'allreFeatures4001.csv', 'allreFeatures5001.csv']\n"
     ]
    }
   ],
   "source": [
    "#append processing results to csv:  #need to add 2000-5000 before appending newest one!\n",
    "import os\n",
    "import glob\n",
    "os.chdir(savetopath + 'allre/')\n",
    "# Produce a single CSV after combining all files\n",
    "def make_one_csv(list_of_files, file_out):\n",
    "   # Consolidate all CSV files into one object\n",
    "   result = pd.concat([pd.read_csv(file) for file in list_of_files])\n",
    "   # Convert the above object into a csv file and export\n",
    "   result.to_csv(file_out, index=False, encoding=\"utf-8\")\n",
    "    \n",
    "#find all csv files in the folder\n",
    "#use glob pattern matching -> extension = 'csv'\n",
    "#save result in list -> all_filenames\n",
    "extension = 'csv'\n",
    "list_of_files = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "print(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T22:45:49.393988Z",
     "start_time": "2019-11-30T22:44:45.370208Z"
    }
   },
   "outputs": [],
   "source": [
    "file_out = \"allreFeatures.csv\"\n",
    "make_one_csv(list_of_files, file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T23:03:37.248779Z",
     "start_time": "2019-11-30T23:03:28.376596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5002, 4097)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aft = pd.read_csv('allreFeatures.csv', header=None)\n",
    "aft.shape #extra column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-30T23:05:36.450695Z",
     "start_time": "2019-11-30T23:05:32.993677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 4097)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aft1 = pd.read_csv('allreFeatures1001.csv', header=None)\n",
    "aft1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should use append to csv instead?? modify aws code with below\n",
    "# savetopath = '/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project/data/processed/'\n",
    "\n",
    "# #append processing results to csv:\n",
    "# if num_start==1:\n",
    "#     res.to_csv(savetopath + 'bbcFeatures.csv')\n",
    "# else:\n",
    "#     with open(savetopath + 'bbcFeatures.csv', 'a') as f:\n",
    "#         res.to_csv(f, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
