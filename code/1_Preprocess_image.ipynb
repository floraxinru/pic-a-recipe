{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:11.631216Z",
     "start_time": "2019-11-29T21:24:07.496564Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras_applications import imagenet_utils\n",
    "#see doc for built-in functions https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py#L157\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:19.017085Z",
     "start_time": "2019-11-29T21:24:11.633823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/anaconda/envs/metis/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import metis_passion_project.src.utils.preprocessing_functions  \n",
    "import metis_passion_project.src.utils.prep_images\n",
    "\n",
    "from metis_passion_project.src.utils.preprocessing_functions import get_images, to_array, cos_sim_vs_all, get_feature_df\n",
    "from metis_passion_project.src.utils.prep_images import convert_image_to_bgr_numpy_array, prepare_image\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:25.267082Z",
     "start_time": "2019-11-29T21:24:19.037243Z"
    }
   },
   "outputs": [],
   "source": [
    "VGG16_top = VGG16(weights='imagenet', include_top=True)\n",
    "modelft = Model(inputs=VGG16_top.input, outputs=VGG16_top.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:25.291664Z",
     "start_time": "2019-11-29T21:24:25.270606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelft.summary()  #useful overview functions for model architecture!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:25.353231Z",
     "start_time": "2019-11-29T21:24:25.297299Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = 'testimages/dog.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:26.651605Z",
     "start_time": "2019-11-29T21:24:25.356185Z"
    }
   },
   "outputs": [],
   "source": [
    "features = modelft.predict(x) #.predict is slow even for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:26.668180Z",
     "start_time": "2019-11-29T21:24:26.657861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "[[0.        0.        6.4011474 ... 3.977399  0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.598774Z",
     "start_time": "2019-11-29T21:24:26.674968Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = 'testimages/8301.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0) #?\n",
    "x = preprocess_input(x) #what is this imported ftn doing?*\n",
    "features = modelft.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.606357Z",
     "start_time": "2019-11-29T21:24:27.601999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(features) #get 0s on the border because image has a different size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.612390Z",
     "start_time": "2019-11-29T21:24:27.608985Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_images(directory):\n",
    "#     #loop through files in directory, directory is file path of folder containing images\n",
    "#     import os\n",
    "#     img_lst = []\n",
    "#     for entry in os.scandir(directory): \n",
    "#         if entry.path == directory + '/.DS_Store':\n",
    "#             continue  #avoid reading mac os's .DS_Store as an image\n",
    "#         else:\n",
    "#             img_lst.append(entry.path)\n",
    "#     return img_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.622644Z",
     "start_time": "2019-11-29T21:24:27.615034Z"
    }
   },
   "outputs": [],
   "source": [
    "#from metis_passion_project.src.utils.preprocessing_functions import progressbar  *try importing again after restarting kernel?\n",
    "import sys\n",
    "def progressbar(it, prefix=\"\", size=60, file=sys.stdout):\n",
    "    count = len(it)\n",
    "    def show(j):\n",
    "        x = int(size*j/count)\n",
    "        file.write(\"%s[%s%s] %i/%i\\r\" % (prefix, \"#\"*x, \".\"*(size-x), j, count))\n",
    "        file.flush()        \n",
    "    show(0)\n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i+1)\n",
    "    file.write(\"\\n\")\n",
    "    file.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.628749Z",
     "start_time": "2019-11-29T21:24:27.625199Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "#for i in progressbar(range(20), \"Computing: \", 40):\n",
    "#    get_feature_index(array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.636853Z",
     "start_time": "2019-11-29T21:24:27.631636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['testimages/muffins/19826.jpg', 'testimages/muffins/2945.jpg', 'testimages/muffins/6423.jpg', 'testimages/muffins/9186.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(get_images('testimages/muffins'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.643659Z",
     "start_time": "2019-11-29T21:24:27.639511Z"
    }
   },
   "outputs": [],
   "source": [
    "images_list = get_images('testimages/muffins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.666922Z",
     "start_time": "2019-11-29T21:24:27.646411Z"
    }
   },
   "outputs": [],
   "source": [
    "array_list = to_array(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.674116Z",
     "start_time": "2019-11-29T21:24:27.671577Z"
    }
   },
   "outputs": [],
   "source": [
    "#VGG16_top = VGG16(weights='imagenet', include_top=True)  #also try inlude_top = False\n",
    "#modelft = Model(inputs=VGG16_top.input, outputs=VGG16_top.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:27.680359Z",
     "start_time": "2019-11-29T21:24:27.676794Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# feature_df = pd.DataFrame()   #make this into a function and export to .py**\n",
    "# for im in array_list:\n",
    "#     im = np.expand_dims(im, axis=0) #is this necessary?\n",
    "#     im = preprocess_input(im) \n",
    "#     features = modelft.predict(im)#x?\n",
    "#     feature_df = feature_df.append(pd.DataFrame(features), ignore_index=True)\n",
    "    \n",
    "#     #roughtly 4s for preprocessing 4 images and putting features in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.668596Z",
     "start_time": "2019-11-29T21:24:27.682972Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_df = pd.DataFrame()   #make this into a function and export to .py** -- this works better than imported ver somehow?\n",
    "for im in array_list:\n",
    "    im = np.expand_dims(im, axis=0) #is this necessary?\n",
    "    im = preprocess_input(im) \n",
    "    features = modelft.predict(im)#x?\n",
    "    feature_df = feature_df.append(pd.DataFrame(features), ignore_index=True)\n",
    "\n",
    "    #add code printout to see how many images have been processed:\n",
    "    #if im % 200 ==0:\n",
    "     #       print(\"Done upto image {}\".format(jpegImg)) doesn't work because im is array here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.726081Z",
     "start_time": "2019-11-29T21:24:31.671155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4086</th>\n",
       "      <th>4087</th>\n",
       "      <th>4088</th>\n",
       "      <th>4089</th>\n",
       "      <th>4090</th>\n",
       "      <th>4091</th>\n",
       "      <th>4092</th>\n",
       "      <th>4093</th>\n",
       "      <th>4094</th>\n",
       "      <th>4095</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.289247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144903</td>\n",
       "      <td>1.764754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.023448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.278557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.346135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.357480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.343498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.504429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.570876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.334681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 4096 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2         3         4     5         6     7     8         9     \\\n",
       "0   0.0   0.0   0.0  0.000000  0.482736   0.0  2.289247   0.0   0.0  0.000000   \n",
       "1   0.0   0.0   0.0  0.144903  1.764754   0.0  5.023448   0.0   0.0  0.000000   \n",
       "2   0.0   0.0   0.0  0.346135  0.000000   0.0  2.357480   0.0   0.0  0.000000   \n",
       "3   0.0   0.0   0.0  0.000000  0.000000   0.0  1.343498   0.0   0.0  1.504429   \n",
       "\n",
       "   ...      4086  4087  4088      4089  4090  4091  4092      4093  4094  4095  \n",
       "0  ...  0.000000   0.0   0.0  0.466059   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
       "1  ...  0.000000   0.0   0.0  2.278557   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
       "2  ...  0.000000   0.0   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0  \n",
       "3  ...  0.439708   0.0   0.0  0.570876   0.0   0.0   0.0  3.334681   0.0   0.0  \n",
       "\n",
       "[4 rows x 4096 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.736260Z",
     "start_time": "2019-11-29T21:24:31.728919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 0.      , 0.      , 0.      ],\n",
       "       [0.      , 0.      , 0.      , ..., 3.334681, 0.      , 0.      ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.values #get array of values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.746220Z",
     "start_time": "2019-11-29T21:24:31.738957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.      , 0.      , 0.      , ..., 3.334681, 0.      , 0.      ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select a single row from df using .loc[]!\n",
    "feature_df.iloc[3].values #2nd row (row index 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.761842Z",
     "start_time": "2019-11-29T21:24:31.749180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(feature_df.iloc[1].values.reshape(1,-1))  #*does have cos sim of 1 with itself! but self-defined function doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.772517Z",
     "start_time": "2019-11-29T21:24:31.769223Z"
    }
   },
   "outputs": [],
   "source": [
    "# def cos_sim_vs_all(imageft, datasetft):\n",
    "#     from sklearn.metrics.pairwise import cosine_similarity\n",
    "#     sim_list = []\n",
    "#     for i in range(len(datasetft)):\n",
    "#         cos_sim = cosine_similarity(imageft, datasetft.iloc[i].values.reshape(1,-1)) \n",
    "#         sim_list.append(cos_sim)\n",
    "#     return sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.793666Z",
     "start_time": "2019-11-29T21:24:31.776967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.8342912]],\n",
       "\n",
       "       [[1.       ]],\n",
       "\n",
       "       [[0.8419672]],\n",
       "\n",
       "       [[0.6739648]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_vs_all(feature_df.iloc[1].values.reshape(1,-1),feature_df)  #works up to here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muffin 1 is most similar with itself, quite similar to 0 and 2, least similar with 3 (#4 in list) - this makes sense to me visually also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.800187Z",
     "start_time": "2019-11-29T21:24:31.796364Z"
    }
   },
   "outputs": [],
   "source": [
    "#Nov 27, test new function to write csv\n",
    "#load features from csv, to use as inputs for cos_sim_vs_all function\n",
    "savetopath ='/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project/data/processed/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.805888Z",
     "start_time": "2019-11-29T21:24:31.802659Z"
    }
   },
   "outputs": [],
   "source": [
    "#get_images()\n",
    "#to_array() -> array_list\n",
    "#get_feature_df(array_list, savetopath)  #still ~4s for 4 images, not much faster than without csv?\n",
    "#3s instead of 4 after commenting out preprocessing_input line in get_features\n",
    "\n",
    "#11/27, 10pm 6s? taking longer? 2nd run, 3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.811774Z",
     "start_time": "2019-11-29T21:24:31.808791Z"
    }
   },
   "outputs": [],
   "source": [
    "#test diff lines in get_feature - preprocessing code\n",
    "#get_feature_df(array_list, savetopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.818324Z",
     "start_time": "2019-11-29T21:24:31.814685Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_feature_test(arraylist, savetopath): #combine with ftn above? keras vgg16 application example\n",
    "#     '''use keras preprocessing functions to process each image and fit on pretrained model with imagenet weights\n",
    "#     Returns a csv file from dataframes of features, 4096 features for each image (before last (top) layer of CNN model)\n",
    "#     Modified from keras docs: https://keras.io/applications/#models-for-image-classification-with-weights-trained-on-imagenet\n",
    "#     '''\n",
    "\n",
    "#     #?\n",
    "\n",
    "#     #*get rid of DF line, put array to csv directly?\n",
    "#     #*use CNN lecture preprocessing code instead?\n",
    "# #* break down preprocess ftn, see which line takes longest*!\n",
    "\n",
    "#     feature_df = pd.DataFrame()   #*save as csv instead!** csv uses memory; df uses RAM\n",
    "#     #how to loop through every 5 or 20 images for df? while loop?\n",
    "#     for im in arraylist:\n",
    "#         im = np.expand_dims(im, axis=0) #is this necessary?\n",
    "#         im = preprocess_input(im) \n",
    "#         features = modelft.predict(im)#x?  #check keras docs? may not need this line\n",
    "#         feature_df = pd.DataFrame(im) #df of one image at a time for now, optimize later\n",
    "#         with open(savetopath, 'a') as f: #define mode as \"a\" . \"A\" stands for APPEND\n",
    "#             feature_df.to_csv(f, mode='a', header=f.tell()==0) #add header when writing to file for the first time\n",
    "#             #should this be in the for loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.827109Z",
     "start_time": "2019-11-29T21:24:31.822445Z"
    }
   },
   "outputs": [],
   "source": [
    "images_list = get_images('testimages/muffins') #4ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:31.844186Z",
     "start_time": "2019-11-29T21:24:31.830161Z"
    }
   },
   "outputs": [],
   "source": [
    "array_list = to_array(images_list) #14ms for four images ~3ms per image\n",
    "#restart kernel, 42ms? 13ms per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.658613Z",
     "start_time": "2019-11-29T21:24:31.846737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 224, 224)\n",
      "(1, 3, 224, 224)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (224, 224, 3) but got array with shape (3, 224, 224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ef9befbae82b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_feature_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavetopath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Metis_bootcamp/week_9/metis_passion_project/src/utils/preprocessing_functions.py\u001b[0m in \u001b[0;36mget_feature_df\u001b[0;34m(arraylist, savetopath)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mfeature_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#df of one image at a time for now, optimize later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavetopath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#define mode as \"a\" . \"A\" stands for APPEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/anaconda/envs/metis/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (224, 224, 3) but got array with shape (3, 224, 224)"
     ]
    }
   ],
   "source": [
    "get_feature_df(array_list, savetopath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.669802Z",
     "start_time": "2019-11-29T21:24:07.601Z"
    }
   },
   "outputs": [],
   "source": [
    "#**\n",
    "#get_feature_test(array_list, savetopath) \n",
    "    #full function, 2.86s for four images ~0.72s/image; 2nd run: 3.28s ~0.82s/image\n",
    "    #no expand_dims, get error ValueError: Error when checking input: expected input_3 to have 4 dimensions, but got array with shape (224, 224, 3)\n",
    "    #without keras preprocessing function (just predict), 2.45, 2.47, 2.52s ~0.61~0.645s/image (still too slow?)\n",
    "\n",
    "    #just process, no predict, 55ms ~14ms/image; 61ms ~15ms\n",
    "    \n",
    "    #14ms per image, 1000 images = 14s?\n",
    "    \n",
    "    \n",
    "#from prev get_features function\n",
    "#features = modelft.predict(im) -- without preprocessing ftn, just predict, get ~0.64ms/image\n",
    "    #100 images, 64s (~1min); 2k images 1280 + ~130 for ~ 1400s = total ~20-30min without preproc ftn? but actually much slower, a lot of overhead (where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.672499Z",
     "start_time": "2019-11-29T21:24:07.604Z"
    }
   },
   "outputs": [],
   "source": [
    " #without keras preprocessing function, 2.45, 2.47, 2.52s ~0.61~0.645s/image (still too slow?)\n",
    "\n",
    "#with preprocessing but without predict, dimensions incorrect - need all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.676262Z",
     "start_time": "2019-11-29T21:24:07.608Z"
    }
   },
   "outputs": [],
   "source": [
    "#read_csv: Read a comma-separated values (csv) file into DataFrame.\n",
    "#instead of hardcoded paths? need to change this for aws code\n",
    "muffin_ft = pd.read_csv('/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project/data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.689813Z",
     "start_time": "2019-11-29T21:24:07.611Z"
    }
   },
   "outputs": [],
   "source": [
    "muffin_ft #7 rows because ran twice, keeps appending onwards, and first row counted as header? \n",
    "#need to initialize file (in or out of function?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.693164Z",
     "start_time": "2019-11-29T21:24:07.614Z"
    }
   },
   "outputs": [],
   "source": [
    "type(muffin_ft.iloc[0].values) #values of df Series values are in an array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.696645Z",
     "start_time": "2019-11-29T21:24:07.618Z"
    }
   },
   "outputs": [],
   "source": [
    "cos_sim_vs_all(muffin_ft.iloc[0].values.reshape(1, -1), muffin_ft)  #use iloc for df indices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results make sense, muffin0 more similar to 1 and 2 compared to 3 (darker colour, flatter shape)\n",
    "\n",
    "Can proceed with larger datasets now (finally)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.698730Z",
     "start_time": "2019-11-29T21:24:07.622Z"
    }
   },
   "outputs": [],
   "source": [
    "muffins = cos_sim_vs_all(muffin_ft.iloc[0].values.reshape(1, -1), muffin_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.709750Z",
     "start_time": "2019-11-29T21:24:07.626Z"
    }
   },
   "outputs": [],
   "source": [
    "type(muffins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.712256Z",
     "start_time": "2019-11-29T21:24:07.629Z"
    }
   },
   "outputs": [],
   "source": [
    "#a = muffins.argsort() #don't use this\n",
    "#argsort not working! but it's the correct data type; why?\n",
    "#should return indices sorted by values, expect [3,1,2,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*write function for this also?*\n",
    "argsort() Returns the indices that would sort an array. Default is quicksort\n",
    "\n",
    "It returns an array of indices of the same shape as a that index data along the given axis in sorted order.\n",
    "\n",
    "axis : [int or None] Axis along which to sort. If None, the array is flattened before sorting. The default is -1, which sorts along the last axis.\n",
    "\n",
    "Example from numpy:\n",
    "```\n",
    "x = np.array([[0, 3], [2, 2]])\n",
    "\n",
    ">>> ind = np.argsort(x, axis=1)  # sorts along last axis (across)\n",
    ">>> ind\n",
    "array([[0, 1],\n",
    "       [0, 1]])\n",
    ">>> np.take_along_axis(x, ind, axis=1)  # same as np.sort(x, axis=1)\n",
    "array([[0, 3],\n",
    "       [2, 2]])\n",
    "       \n",
    "       \n",
    "       \n",
    ">>> ind = np.argsort(x, axis=0)  # sorts along first axis (down)\n",
    ">>> ind\n",
    "array([[0, 1],\n",
    "       [1, 0]])\n",
    ">>> np.take_along_axis(x, ind, axis=0)  # same as np.sort(x, axis=0)\n",
    "array([[0, 2],\n",
    "       [2, 3]])\n",
    "       ```\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.715919Z",
     "start_time": "2019-11-29T21:24:07.632Z"
    }
   },
   "outputs": [],
   "source": [
    "a = muffins.argsort(axis=None)  #was probably sorting by some other axis, use this in .py function instead!\n",
    "a \n",
    "#can connect image indicies to recipe titles later? or make image titles the indicies? - works for bbc set with recipe names as image title, but not for allr set where image titles are numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.718075Z",
     "start_time": "2019-11-29T21:24:07.635Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.fliplr(a) #Requires the array to be at least 2-D! use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take one pie photo, compare cosine similarity with the rest of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets\n",
    "\n",
    "allrecipes.com: 91K recipes, with photos, HTML, and crawling code\n",
    "epicurious.com: 34K recipes, with photos, JSON, and crawling code\n",
    "bbc.co.uk: 10K recipes, with photos, HTML, and crawling code\n",
    "cookstr.com: 8K recipes, with photos, HTML, and crawling code -- need to change file extensions first\n",
    "\n",
    "Wanted to start with bbc set, but not many pies. Previously got 0.75 with allrecipes data (largest, 35,300 items in 250x250 folderm ~same with epicurious set), Will likely merge all of them eventually anyway.\n",
    "\n",
    "Try to find similar pictures in BBC set for: apple pie (perfect_apple_pie_73735_16x9.jpg) and roast turkey (perfect_roast_turkey_72482_16x9.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.720285Z",
     "start_time": "2019-11-29T21:24:07.643Z"
    }
   },
   "outputs": [],
   "source": [
    "#hardcode local path, better way?\n",
    "#load_or_make.py, pickle data?\n",
    "path = '/Users/xinrucheng/Documents/Metis_bootcamp/week_9/project5data/2017_140k/recipe_photos/bbc_photos/pages-photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.722180Z",
     "start_time": "2019-11-29T21:24:07.646Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = path + '/perfect_apple_pie_73735_16x9.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.725135Z",
     "start_time": "2019-11-29T21:24:07.649Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.738365Z",
     "start_time": "2019-11-29T21:24:07.652Z"
    }
   },
   "outputs": [],
   "source": [
    "x = preprocess_input(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.743893Z",
     "start_time": "2019-11-29T21:24:07.655Z"
    }
   },
   "outputs": [],
   "source": [
    "fts = modelft.predict(x)\n",
    "\n",
    "applepie_ft = fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.746202Z",
     "start_time": "2019-11-29T21:24:07.658Z"
    }
   },
   "outputs": [],
   "source": [
    "type(applepie_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.748435Z",
     "start_time": "2019-11-29T21:24:07.661Z"
    }
   },
   "outputs": [],
   "source": [
    "#split cells to see which line in get_features takes the longest\n",
    "img_path = path + '/perfect_roast_turkey_72482_16x9.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))  #put this in a ftn to loop through filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.750379Z",
     "start_time": "2019-11-29T21:24:07.664Z"
    }
   },
   "outputs": [],
   "source": [
    "x = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.752583Z",
     "start_time": "2019-11-29T21:24:07.667Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.754680Z",
     "start_time": "2019-11-29T21:24:07.670Z"
    }
   },
   "outputs": [],
   "source": [
    "x = preprocess_input(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.756933Z",
     "start_time": "2019-11-29T21:24:07.673Z"
    }
   },
   "outputs": [],
   "source": [
    "fts1 = modelft.predict(x) #predict takes the longest, nothing I can do about it though*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.761309Z",
     "start_time": "2019-11-29T21:24:07.676Z"
    }
   },
   "outputs": [],
   "source": [
    "turkey_ft = fts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.765069Z",
     "start_time": "2019-11-29T21:24:07.680Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_similarity(turkey_ft, applepie_ft) #inputs are arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.768722Z",
     "start_time": "2019-11-29T21:24:07.683Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_similarity(turkey_ft, turkey_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.774724Z",
     "start_time": "2019-11-29T21:24:07.686Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_similarity(applepie_ft, applepie_ft) #makes sense features are most similar to itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.776966Z",
     "start_time": "2019-11-29T21:24:07.695Z"
    }
   },
   "outputs": [],
   "source": [
    "# img_path = path + '/perfect_roast_turkey_72482_16x9.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))  #put this in a ftn to loop through filenames\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0) \n",
    "# x = preprocess_input(x) \n",
    "# fts1 = modelft.predict(x)\n",
    "\n",
    "# turkey_ft = fts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.779585Z",
     "start_time": "2019-11-29T21:24:07.698Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_fta(arraylist): \n",
    "#     #from keras.applications.vgg16 import VGG16\n",
    "#     #from keras.models import Model\n",
    "#     #import pandas as pd\n",
    "    \n",
    "#     ft_arr = []\n",
    "#     #VGG16_top = VGG16(weights='imagenet', include_top=True)\n",
    "#     #modelft = Model(inputs=VGG16_top.input, outputs=VGG16_top.get_layer('fc2').output)\n",
    "    \n",
    "#     for im in arraylist:\n",
    "#         #im = np.expand_dims(im, axis=0) #is this necessary?\n",
    "#         im = preprocess_input(im)  #built-in, scales image also?\n",
    "#         features = modelft.predict(im)\n",
    "#         ft_arr = ft_arr.append(features)\n",
    "#     return np.array(ft_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.781996Z",
     "start_time": "2019-11-29T21:24:07.701Z"
    }
   },
   "outputs": [],
   "source": [
    "im.shape #does have 4 dimensions, maybe im needs to be returned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.783840Z",
     "start_time": "2019-11-29T21:24:07.704Z"
    }
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.785795Z",
     "start_time": "2019-11-29T21:24:07.707Z"
    }
   },
   "outputs": [],
   "source": [
    "#cos_sim_vs_all(muf_df.iloc[1].values.reshape(1,-1),muf_df)  #diff data type?  1 array or list of 4 arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- now getting different values compared to before? what changed? get_feature_df function, but should be identical in jupyter or imported!\n",
    "```\n",
    "[array([[0.79974574]], dtype=float32),\n",
    " array([[1.]], dtype=float32),\n",
    " array([[0.8104253]], dtype=float32),\n",
    " array([[0.6055574]], dtype=float32)]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.787799Z",
     "start_time": "2019-11-29T21:24:07.710Z"
    }
   },
   "outputs": [],
   "source": [
    "#get_ft_df(test2) #16s for 4 images, slower than before?\n",
    "# when importing ftn or on aws machine: \"ValueError: Error when checking input: expected input_3 to have 4 dimensions, but got array with shape (1, 1, 4096)\"\n",
    "\n",
    "#why 4 instead of 2 rows? not repeated from above either; already restarted jupyter\n",
    "\n",
    "    #np.resize(img, (-1, <image shape>) #*need to reshape arrays too?\n",
    "    \n",
    "#np.resize(img, (-1, 224,224,3)  #*which input is expected to have 4 dimensions? input_n in error message keeps changing\n",
    "\n",
    "#Nov 26 new error: \n",
    "#ValueError: Error when checking input: expected input_4 to have 4 dimensions, but got array with shape (1, 4096)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.789830Z",
     "start_time": "2019-11-29T21:24:07.713Z"
    }
   },
   "outputs": [],
   "source": [
    "# # from above\n",
    "# def cos_sim_vs_all(imageft, datasetft):\n",
    "#     from sklearn.metrics.pairwise import cosine_similarity\n",
    "#     sim_list = []\n",
    "#     for i in range(len(datasetft)):\n",
    "#         cos_sim = cosine_similarity(imageft, datasetft.loc[i].values.reshape(1,-1)) #change to iloc?\n",
    "#         #datasetft needs to be df for this to work - use output from get_ft_df\n",
    "#             #better if take in array and matrix?\n",
    "#         sim_list.append(cos_sim)\n",
    "#     return sim_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.791884Z",
     "start_time": "2019-11-29T21:24:07.716Z"
    }
   },
   "outputs": [],
   "source": [
    "#cos_sim_vs_all(turkey_ft, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.794392Z",
     "start_time": "2019-11-29T21:24:07.719Z"
    }
   },
   "outputs": [],
   "source": [
    "#cos_sim_vs_all(turkey_ft, applepie_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.797438Z",
     "start_time": "2019-11-29T21:24:07.722Z"
    }
   },
   "outputs": [],
   "source": [
    "#cos_sim_vs_all(turkey_ft, turkey_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.801507Z",
     "start_time": "2019-11-29T21:24:07.725Z"
    }
   },
   "outputs": [],
   "source": [
    "#for a single image, results make sense (most similar to itself, cos sim~1! Something wrong with looping code, or uploading/importing to aws?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.803972Z",
     "start_time": "2019-11-29T21:24:07.729Z"
    }
   },
   "outputs": [],
   "source": [
    "#hardcode local path, better way?\n",
    "#load_or_make.py, pickle data?\n",
    "bbcpath = '/Users/xinrucheng/Documents/Metis_bootcamp/week_9/project5data/2017_140k/recipe_photos/bbc_photos/pages-photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.810077Z",
     "start_time": "2019-11-29T21:24:07.732Z"
    }
   },
   "outputs": [],
   "source": [
    "#bbcpath has 2226 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.812306Z",
     "start_time": "2019-11-29T21:24:07.735Z"
    }
   },
   "outputs": [],
   "source": [
    "test_bbc = get_images(bbcpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.816348Z",
     "start_time": "2019-11-29T21:24:07.738Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in progressbar(range(20), \"Computing: \", 40):\n",
    "    array_list = to_array(test_bbc) #using over 7GB RAM at 11/20 - activity monitor goes red* - save arrays of images as csv also?*\n",
    "    \n",
    "    #with more images, saving to csv is much faster (yay), ~2 min for 4/20 => 10 min for all? actually took 5mins\n",
    "    \n",
    "    #after removing preprocessing line, to_array is still ~ 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.819253Z",
     "start_time": "2019-11-29T21:24:07.741Z"
    }
   },
   "outputs": [],
   "source": [
    "#VGG16_top = VGG16(weights='imagenet', include_top=True)\n",
    "#modelft = Model(inputs=VGG16_top.input, outputs=VGG16_top.get_layer('fc2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.820826Z",
     "start_time": "2019-11-29T21:24:07.745Z"
    }
   },
   "outputs": [],
   "source": [
    "savetopath ='/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project/data/processed/bbcft.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.834178Z",
     "start_time": "2019-11-29T21:24:07.748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in progressbar(range(20), \"Computing: \", 40):\n",
    "    bbc_df = get_feature_df(array_list, savetopath) \n",
    "    #Nov 27 14:27, trying again with updated ftns, saving df to csv (saved to disk) this time, less pressure on RAM\n",
    "    #doesn't seem that much faster initially, but memory pressure on activity monitor is green at least\n",
    "    \n",
    "    #still taking too long? 1/20 ~ 20-30mins, total could be  on local machine, try AWS again\n",
    "    \n",
    "    #started with new get_features ftn at 16:10 \n",
    "        #after appending each image to csv, still slow! how to grab multiple rows in df to csv?\n",
    "        \n",
    "    #moved csv to inside for loop in get_features, commented out preprocessing_input, started this cell at 16:44\n",
    "    #if 1s per image, 1/20~100 images should take <2mins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.836104Z",
     "start_time": "2019-11-29T21:24:07.751Z"
    }
   },
   "outputs": [],
   "source": [
    "#first 1000 of bbc set? also try first 1000 of allrecipes set\n",
    "#30mins for 1000 pictures on local machine   #afternoon: took 50mins on local machine??***\n",
    "\n",
    "#started again at 19:36, only 7/20 done by 11pm; \n",
    "#aborted and restarted, finished 6:30am - ~7hrs, why so slow?? (kernel dies on aws)\n",
    "#actually ~7hours for entire bbc images data, 2226 images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.843357Z",
     "start_time": "2019-11-29T21:24:07.754Z"
    }
   },
   "outputs": [],
   "source": [
    "#check keras doc/blog? maybe use include_top = False instead in model?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.845615Z",
     "start_time": "2019-11-29T21:24:07.757Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = path + '/perfect_roast_turkey_72482_16x9.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))  #put this in a ftn to loop through filenames\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0) \n",
    "x = preprocess_input(x) \n",
    "fts1 = modelft.predict(x)\n",
    "\n",
    "turkey_ft = pd.DataFrame(fts1)  #prev, array, change to df to feed into cos_sim_vs_all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.848640Z",
     "start_time": "2019-11-29T21:24:07.760Z"
    }
   },
   "outputs": [],
   "source": [
    "turkey_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.852059Z",
     "start_time": "2019-11-29T21:24:07.764Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in progressbar(range(20), \"Computing: \", 40):\n",
    "    cos_sim_vs_all(turkey_ft,turkey_ft)  #similarity with itself is 1!\n",
    "cos_sim_vs_all(turkey_ft,turkey_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.856264Z",
     "start_time": "2019-11-29T21:24:07.766Z"
    }
   },
   "outputs": [],
   "source": [
    "#need to read out bbcfeatures csv before comparing! (also shouldn't call it df anymore)\n",
    "#can write another function?\n",
    "bbc_ft = pd.read_csv('/Users/xinrucheng/Documents/Metis_bootcamp/week_9/metis_passion_project/data/processed/bbcft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.857919Z",
     "start_time": "2019-11-29T21:24:07.772Z"
    }
   },
   "outputs": [],
   "source": [
    "#change function to save similarities as df instead of array?\n",
    "for i in progressbar(range(20), \"Computing: \", 40):\n",
    "    \n",
    "    cos_sim_vs_all(turkey_ft,bbc_df)  \n",
    "cos_sim_vs_all(turkey_ft,bbc_df)\n",
    "    #low similarity, but weird sorting prob is gone in similarity results\n",
    "#choose something in first 200 images to compare against? bakewell tart\n",
    "#should be able to use argsort on this?* got error earlier but was probably problem with cos_sim ftn itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.860945Z",
     "start_time": "2019-11-29T21:24:07.780Z"
    }
   },
   "outputs": [],
   "source": [
    "#keep list above, change to array, might get argsort working to see most similar pics**\n",
    "#turkey_ar = np.array(turkey_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.862531Z",
     "start_time": "2019-11-29T21:24:07.784Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = bbcpath + '/bakewelltart_89618_16x9.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224)) \n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0) \n",
    "x = preprocess_input(x) \n",
    "fts1 = modelft.predict(x)\n",
    "#keras applications doc; similar to what get_features does\n",
    "\n",
    "tart_ft = pd.DataFrame(fts1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.866308Z",
     "start_time": "2019-11-29T21:24:07.787Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in progressbar(range(20), \"Computing: \", 40):\n",
    "    cos_sim_vs_all(tart_ft,bbc_df)  \n",
    "cos_sim_vs_all(tart_ft,bbc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.868969Z",
     "start_time": "2019-11-29T21:24:07.792Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in progressbar(range(20), \"Computing: \", 40):\n",
    "#     cos_sim_vs_all(turkey_ft.values.reshape(1,-1),bbc_df) #get same output as above, reshape not necessary - not throwing an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.871130Z",
     "start_time": "2019-11-29T21:24:07.795Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in progressbar(range(20), \"Computing: \", 40):\n",
    "    tart_sim = cos_sim_vs_all(tart_ft,tart_ft) \n",
    "#turkey_sim #.argsort() only works for arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.873567Z",
     "start_time": "2019-11-29T21:24:07.798Z"
    }
   },
   "outputs": [],
   "source": [
    "type(tart_sim) #want an array for sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> argsort() documentations: Input array - arr : [array_like] \n",
    "Return : [index_array, ndarray] Array of indices that sort arr along the specified axis.If arr is one-dimensional then arr[index_array] returns a sorted arr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.876214Z",
     "start_time": "2019-11-29T21:24:07.810Z"
    }
   },
   "outputs": [],
   "source": [
    "turkey_ar = np.array(turkey_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.878341Z",
     "start_time": "2019-11-29T21:24:07.813Z"
    }
   },
   "outputs": [],
   "source": [
    "a = turkey_ar.argsort() #*need cos_sim features as a dataframe? \n",
    "#df of get_features not indexed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.880511Z",
     "start_time": "2019-11-29T21:24:07.816Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.fliplr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.883212Z",
     "start_time": "2019-11-29T21:24:07.820Z"
    }
   },
   "outputs": [],
   "source": [
    "#change to array and argsort?\n",
    "\n",
    "#reverse order\n",
    "#argsort returns sorted array pf indices with their values from low to high \n",
    "# lsa_s_choc_ctv.argsort()\n",
    "# Out[65]:\n",
    "# array([[80276, 98585, 63735, ...,  5450, 35999,     3]])\n",
    "# In [66]:\n",
    "# a = lsa_s_choc_ctv.argsort()\n",
    "# np.fliplr(a) #flip array sorted by argsort, slower though\n",
    "\n",
    "# #expect the first result to be the recipe itself [3], with cosine similarity=1\n",
    "# Out[66]:\n",
    "# array([[    3, 35999,  5450, ..., 63735, 98585, 80276]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.884550Z",
     "start_time": "2019-11-29T21:24:07.823Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_feature_index(arraylist):\n",
    "#     '''use keras preprocessing functions to process each image and fit on pretrained model with imagenet weights\n",
    "#     returns a dataframe of features, 4096 features for each image (before last (top) layer of CNN model)'''\n",
    "#     feature_df = pd.DataFrame()   #save as csv instead?\n",
    "#     for im in arraylist:\n",
    "#         im = np.expand_dims(im, axis=0) #is this necessary?\n",
    "#         im = preprocess_input(im) \n",
    "#         #print(im.shape)\n",
    "#         features = modelft.predict(im)#x?\n",
    "#         feature_df = feature_df.append(pd.DataFrame(features), ignore_index=False)\n",
    "#     return feature_df  #(crashed on typo above, didn't run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.887850Z",
     "start_time": "2019-11-29T21:24:07.828Z"
    }
   },
   "outputs": [],
   "source": [
    "#try enumerate?\n",
    "# def cos_sim(imageft, datasetft):\n",
    "#     '''Find the pairwise cosine similarity between features of the chosen image and all the images in the dataset'''\n",
    "#     sim_list = []\n",
    "#     for i in enumerate(datasetft):\n",
    "#         cos_sim = cosine_similarity(imageft, datasetft.iloc[i].reshape(1,-1))\n",
    "#         sim_list.append(cos_sim)\n",
    "#     return np.array(sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.893720Z",
     "start_time": "2019-11-29T21:24:07.831Z"
    }
   },
   "outputs": [],
   "source": [
    "#testmuffin = cos_sim(muffin_df.iloc[0], muffin_df) #AttributeError: 'numpy.float32' object has no attribute 'values'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.897433Z",
     "start_time": "2019-11-29T21:24:07.834Z"
    }
   },
   "outputs": [],
   "source": [
    "#turkey_sim = cos_sim_vs_all(muffin_df.iloc[0].values.reshape(1,-1),muffin_df) #throws error here if don't do reshape for one row\n",
    "#new dim error on df, but comparing each element with the first muffin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Test a portion of allrecipes images instead (more similar? but total of 35000 images is too big for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.899324Z",
     "start_time": "2019-11-29T21:24:07.837Z"
    }
   },
   "outputs": [],
   "source": [
    "arpath = '/Users/xinrucheng/Documents/Metis_bootcamp/week_9/project5data/2017_140k/recipe_photos/allre_images/userphotos/250x250'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.901176Z",
     "start_time": "2019-11-29T21:24:07.841Z"
    }
   },
   "outputs": [],
   "source": [
    "#**ran on AWS, took longer than 2 hours for get_features for first 1000 of allrecipes set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.903925Z",
     "start_time": "2019-11-29T21:24:07.846Z"
    }
   },
   "outputs": [],
   "source": [
    "#base_model = VGG16(weights='imagenet', include_top=False, input_shape=(3,250,250)) #include_top=False - dropped final layer of base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.905735Z",
     "start_time": "2019-11-29T21:24:07.849Z"
    }
   },
   "outputs": [],
   "source": [
    "#using keras imagenet_utils functions to preprocess images\n",
    "'''\n",
    "def preprocess_input(x, data_format=None, mode='caffe', **kwargs):\n",
    "    #Preprocesses a tensor or Numpy array encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: Input Numpy or symbolic tensor, 3D or 4D.\n",
    "            The preprocessed data is written over the input data\n",
    "            if the data types are compatible. To avoid this\n",
    "            behaviour, `numpy.copy(x)` can be used.\n",
    "        data_format: Data format of the image tensor/array.\n",
    "        mode: One of \"caffe\", \"tf\" or \"torch\".\n",
    "            - caffe: will convert the images from RGB to BGR,\n",
    "                then will zero-center each color channel with\n",
    "                respect to the ImageNet dataset,\n",
    "                without scaling. -> VGG16\n",
    "            - tf: will scale pixels between -1 and 1,\n",
    "                sample-wise.\n",
    "            - torch: will scale pixels between 0 and 1 and then\n",
    "                will normalize each channel with respect to the\n",
    "                ImageNet dataset.\n",
    "    # Returns\n",
    "        Preprocessed tensor or Numpy array.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-29T21:24:32.908070Z",
     "start_time": "2019-11-29T21:24:07.852Z"
    }
   },
   "outputs": [],
   "source": [
    "#feature_list = gen_features(array_list) #got similar error in test_CNN, dim3 instead of 2 for cos sim, how to fix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which preprocessing functions to use?\n",
    "https://stackoverflow.com/questions/48677128/what-is-the-right-way-to-preprocess-images-in-keras-while-fine-tuning-pre-traine?rq=1\n",
    "\n",
    "The input to applications.*.preprocess_input is always RGB. If a model expects BGR input, the channels will be permuted inside preprocess_input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
